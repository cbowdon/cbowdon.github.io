{
  "hash": "e87e82f47b3af91a960c17f7373c8f79",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Using Stan from R\"\nauthor: \"Chris Bowdon\"\ndate: \"2024-12-26\"\ncategories: [bayesian, r, stan]\n---\n\n\n\n\nI've been trying to get the hang of Bayesian models with Stan. One of the hurdles has been using Stan from R, so in this post I'm jotting down what I've learned (mostly the hard way).\n\n# RStan or CmdStanR?\n\nOn the whole I had a much better time using `CmdStanR` than `RStan`. When I made a mistake that led to a runtime exception, RStan would simply die with this kind of error:\n\n```\nError in `unserialize()`:\n! error reading from connection\n     ▆\n  1. └─rstan::stan(...)\n  2.   ├─rstan::sampling(...)\n  3.   └─rstan::sampling(...)\n  4.     └─rstan (local) .local(object, ...)\n  5.       └─parallel::parLapplyLB(cl, X = 1:chains, fun = callFun)\n  6.         ├─base::do.call(...)\n  7.         └─parallel::clusterApplyLB(...)\n  8.           └─parallel:::dynamicClusterApply(cl, fun, length(x), argfun)\n  9.             └─parallel:::recvOneResult(cl)\n 10.               ├─parallel::recvOneData(cl)\n 11.               └─parallel:::recvOneData.SOCKcluster(cl)\n 12.                 └─base::unserialize(socklist[[n]])\n ```\n\nCmdStanR on the other hand would print something useful. Other aspects of the development experience were also nicer:\n\n- better status updates (e.g. showing when compiling)\n- editor support for stan files e.g. linting\n\nI found installing CmdStanR, Stan and the rest of the toolchain from Macports to be very easy. However your mileage may vary when it comes to getting an R installation from Macports, due to some esoteric g95 and xcode compiler errors. I ended up having to [locate the R and R-group files on my system and edit them](https://trac.macports.org/ticket/71068). Hopefully the Macports team will resolve this, because I really appreciate being able to install R from there.\n\n# \"Rejecting initial value\" errors\n\nI got \"Rejecting initial value\" a lot:\n\n> log probability evaluates to log(0), i.e. negative infinity\n\nThis is trying to tell you that the default initial value chosen by Stan has a probability of zero in your prior. You need to set constraints in the parameters block that match the prior distribution you choose. For example if you chose a uniform(1, 10) prior, you should add the constraint `<lower=1, upper=10>` to your parameter declaration.\n\n# Don't forget to set `parallel_chains`\n\nOn my system `getOption(\"mc.cores\")` was unset and Stan defaulted to running all four chains on a single core. Oops. You can also have within-chain parallelism, but I've read varying accounts on the usefulness of this (presumably there's more communication required, which is usually the death of parallelism gains).\n\nOther software can apparently use GPUs for calculations by the way (e.g. the TensorFlow-based software) so if you have massive calculations to do those may be worth investigating.\n\n# Maximum tree-depth warnings\n\nHitting maximum tree-depth for the majority of samples was because of an _identifiability_ problem in my model.\n\nThe linked advice within the warning is fairly clear: https://mc-stan.org/misc/warnings#maximum-treedepth. If you're wondering whether your Rhat and ESS values are good, read higher up that page.\n\n# Resolving unidentified or weakly-identified models\n\nI don't have a comprehensive understanding of this, but the general idea is that your problem doesn't have a unique solution, or more precisely there are multiple parameter values that would give the same distribution of observed data. Here's a dumb example: imagine you are modelling your data as draws from a Normal distribution where the mean is the sum of two parameters, i.e. `observations ~ normal(a + b, 1)`. In this case `a` and `b` could be all over the place and the model will struggle. You need to constrain the parameters.\n\nA simple way to do this is to transform your parameters with the inverse logistic function, which has a range (output) between 0 and 1. You could also pin one of your parameters to a constant, though I found that harder to follow and more difficult to make work.\n\nHere's an example from my F1 project, simplified slightly.\n\n\n\n\n```{default}\n#| label: stan-constraints-example\ndata {\n  int<lower=1> n_ctrs;\n  int<lower=1> n_drvs;\n  int<lower=1> n_obs;\n  array[n_obs] int<lower=1, upper=20> positions;\n  array[n_obs, 2] int position_indices;\n}\nparameters {\n  // Raw will be sampled from prior distribution\n  vector[n_ctrs] lambda_ctrs_raw;\n  vector[n_drvs] lambda_drvs_raw;\n  real<lower=0> sigma;\n}\ntransformed parameters {\n  // Transformed will be used as the parameter\n  vector[n_ctrs] lambda_ctrs;\n  vector[n_drvs] lambda_drvs;\n  \n  // The transformed params can only be between 1 and 10\n  // because the inv_logit function has range [0, 1]\n  lambda_ctrs = 1 + 9 * inv_logit(lambda_ctrs_raw);\n  lambda_drvs = 1 + 9 * inv_logit(lambda_drvs_raw);\n}\nmodel {\n  lambda_ctrs_raw ~ std_normal();\n  lambda_drvs_raw ~ std_normal();\n  sigma ~ std_normal();\n  \n  for (k in 1 : n_obs) {\n    int i = position_indices[k, 1];\n    int j = position_indices[k, 2];\n    positions[k] ~ normal(exp(lambda_ctrs[i] + lambda_drvs[j]), sigma);\n  }\n```\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}