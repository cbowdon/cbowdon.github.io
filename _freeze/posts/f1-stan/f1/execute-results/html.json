{
  "hash": "fef1e4ac79d83fbc54aa708f0e8f8946",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Latent skill of F1 drivers: fun with Bayesian models\"\nauthor: \"Chris Bowdon\"\ndate: \"2024-12-23\"\ncategories: [bayesian, r, f1]\n---\n\n\n\n\nI want to play now. Using [Ergast](https://ergast.com/mrd/) data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nqualifying <- read_csv(\"data/qualifying.csv\") |> rename(quali_position = position)\nraces <- read_csv(\"data/races.csv\") |> select(raceId, year, round, circuitId)\nresults <- read_csv(\"data/results.csv\") |> select(resultId, raceId, driverId, constructorId, grid, position, points, milliseconds)\nconstructors <- read_csv(\"data/constructors.csv\") |> select(constructorId, constructorRef)\ndrivers <- read_csv(\"data/drivers.csv\") |> select(driverId, driverRef)\n\nf1data <- races |>\n  merge(results) |>\n  merge(qualifying) |>\n  merge(constructors) |>\n  merge(drivers) |>\n  select(raceId, circuitId, year, round, constructorRef, driverRef, q1, q2, q3, quali_position, grid, position) |>\n  mutate(position = ifelse(position == \"\\\\N\", NA, as.numeric(position)))\n```\n:::\n\n\n\n\n# Model\n\nMy model is an imitation of the f1-metrics model. We have latent variables of driver skill and car quality, which predict points. However I never did get hold of the paper for that, and am instead following the amazing [Rasmus Bååth's blog](https://www.sumsar.net/blog/2013/07/modeling-match-results-in-la-liga-part-one/).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf2024 <- f1data |> filter(year == 2024)\n\nggplot(f2024) +\n  aes(x = position) +\n  facet_wrap(vars(driverRef)) +\n  geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 48 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](f1_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(f2024) +\n  aes(x = position) +\n  facet_wrap(vars(constructorRef)) +\n  geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 48 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](f1_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n:::\n\n\n\n\nPoints is simulated as a draw from a Poisson distribution parameterised by the driver performance and constructor performance.\n\n$$\n\\text{points} \\sim \\text{Poisson}(\\text{perf}_{\\text{drv}} + \\text{perf}_{\\text{ctr}})\n$$\n\nDriver performance is simulated as a draw from a normal distribution.\n\n$$\n\\text{perf}_{\\text{drv}} \\sim \\text{Normal}(\\mu_{\\text{drv}}, \\sigma_{\\text{drv}}^2)\n$$\n\nLikewise constructor performance is simulated as a draw from a normal distribution.\n\n$$\n\\text{perf}_{\\text{ctr}} \\sim \\text{Normal}(\\mu_{\\text{ctr}}, \\sigma_{\\text{ctr}}^2)\n$$\n\nWe will therefore have a likelihood function that is the product of the Poisson density of the points for each driver for each race. The number of parameters is very high, as a performance score for each driver and for each constructor.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_likelihood <- function(drv_race_pts, drv_perf, ctr_perf) {\n  ... # whew\n}\n```\n:::\n\n\n\n\n# Car performance\n\nLet's start simpler, with a view of the car performance. Assume that at least one driver for every constructor maximised the car's performance each weekend. THIS ISN'T TRUE. If Albon had a poor weekend, Sargeant wasn't going to step up, as one of many examples on the grid in 2024. However it is a useful approximation.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nctr_positions <- f2024 |>\n  group_by(round, constructorRef) |>\n  summarise(quali_position = max(quali_position), position = min(position)) |>\n  mutate(\n    # re-rank\n    quali_position = rank(quali_position),\n    position = rank(position)\n  ) |>\n  arrange(round, position)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'round'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(ctr_positions) +\n  aes(x = position) +\n  facet_wrap(vars(constructorRef)) +\n  geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](f1_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\nAgain we simulate the points $p$ as a draw from a Poisson distribution, this time where $\\lambda_\\text{ctr}$ is the performance of the constructor only.\n\n$$\np \\sim \\text{Poisson}(\\lambda_{\\text{ctr}})\n$$\n\nAgain we assume a normal distribution for the performance of the constructors.\n\n$$\n\\lambda_{ctr} \\sim \\text{Normal}(\\mu_{\\text{ctr}}, \\sigma_{\\text{ctr}}^2)\n$$\n\nThen our likelihood function is much simpler.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_lik_ctr <- function(ctr_positions, ctr_perfs) {\n  ctrs <- sort(unique(ctr_positions$constructorRef))\n  log_lik <- 1.0\n  for (i in 1:length(ctrs)) {\n    race_posns <- filter(ctr_positions, constructorRef == ctrs[i])$position\n    log_lik <- log_lik + sum(dpois(race_posns, lambda = ctr_perfs[i], log = TRUE))\n  }\n  log_lik\n}\n```\n:::\n\n\n\n\nLet's throw Stan at this now.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstan)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: StanHeaders\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nrstan version 2.32.6 (Stan version 2.32.2)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'rstan'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:tidyr':\n\n    extract\n```\n\n\n:::\n\n```{.r .cell-code}\noptions(mc.cores = parallel::detectCores())\nrstan_options(auto_write = TRUE)\n\nctrs <- sort(unique(ctr_positions$constructorRef))\nctr_index <- tibble(\n  constructorId = 1:length(ctrs),\n  constructorRef = ctrs,\n)\n\ntidy_ctr_posns <- ctr_positions |> merge(ctr_index)\n\ndata_list <- list(\n  n_ctrs = n_distinct(tidy_ctr_posns$constructorId),\n  n_obs = nrow(tidy_ctr_posns),\n  ctrs = tidy_ctr_posns$constructorId,\n  positions = tidy_ctr_posns$position\n)\n\nlibrary(cmdstanr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThis is cmdstanr version 0.8.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- CmdStan path: /Users/cbowdon/.cmdstan/cmdstan-2.36.0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- CmdStan version: 2.36.0\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(bayesplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThis is bayesplot version 1.11.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- Online documentation and vignettes at mc-stan.org/bayesplot\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- bayesplot theme set to bayesplot::theme_default()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n   * Does _not_ affect other ggplot2 plots\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n   * See ?bayesplot_theme_set for details on theme setting\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_cmdstan_toolchain(fix = TRUE, quiet = TRUE)\n\ndo.stan <- function() {\n  mod <- cmdstan_model(\"f1.stan\")\n  mod$sample(data_list)\n}\nfit <- do.stan()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning MCMC with 4 chains, at most 12 in parallel...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.1 seconds.\nChain 2 finished in 1.1 seconds.\nChain 3 finished in 1.1 seconds.\nChain 4 finished in 1.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.1 seconds.\nTotal execution time: 1.3 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\nmcmc_hist(fit$draws(\"lambda\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](f1_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndf <- fit$draws(\"lambda\", format=\"draws_matrix\") |> as.data.frame()\ncolnames(df) <- ctrs\n\nggplot(pivot_longer(df, ctrs)) +\n  aes(x=value, fill=\"blue\", colour=\"black\") +\n  facet_wrap(vars(name)) +\n  geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %>% select(ctrs)\n\n  # Now:\n  data %>% select(all_of(ctrs))\n\nSee <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](f1_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::",
    "supporting": [
      "f1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}