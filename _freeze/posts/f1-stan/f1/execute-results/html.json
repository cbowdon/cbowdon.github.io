{
  "hash": "45c53bc46de11884ef2cbd9500e8b96a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Latent skill of F1 drivers: fun with Bayesian models\"\nauthor: \"Chris Bowdon\"\ndate: \"2024-12-27\"\ncategories: [bayesian, r, f1]\nwarning: false\n---\n\n\n\nFor a bit of fun, let's try and model the performance of F1 drivers and constructors using Bayesian models. This is of course using data from the fantastic [Ergast](https://ergast.com/mrd/).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nqualifying <- read_csv(\"data/qualifying.csv\") |> rename(quali_position = position)\nraces <- read_csv(\"data/races.csv\") |>\n  select(raceId, year, round, circuitId, name) |>\n  rename(gp = name)\nresults <- read_csv(\"data/results.csv\") |> select(resultId, raceId, driverId, constructorId, grid, position, points, milliseconds)\nconstructors <- read_csv(\"data/constructors.csv\") |> select(constructorId, constructorRef)\ndrivers <- read_csv(\"data/drivers.csv\") |> select(driverId, driverRef)\n\nf1data <- races |>\n  merge(results) |>\n  merge(qualifying) |>\n  merge(constructors) |>\n  merge(drivers) |>\n  select(raceId, gp, year, round, constructorRef, driverRef, q1, q2, q3, quali_position, grid, position) |>\n  mutate(position = ifelse(position == \"\\\\N\", NA, as.numeric(position)))\n```\n:::\n\n\n\nMy model is an imitation of the f1-metrics model. We have latent variables of driver skill and car quality, which predict points. However I never did get hold of the paper for that, and am instead following the amazing [Rasmus Bååth's blog](https://www.sumsar.net/blog/2013/07/modeling-match-results-in-la-liga-part-one/) where he models the latent skill of football teams in La Liga.\n\nIn the interests of being educational - and because Lord knows I hate editing - I am writing this post as I go, including any blind-alleys and debugging.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf2024 <- f1data |> filter(year == 2024)\n\nggplot(f2024) +\n  aes(x = position) +\n  facet_wrap(vars(driverRef)) +\n  geom_histogram(fill = \"dodgerblue4\", alpha = 0.5, colour = \"black\", linewidth = 0.1)\n\nggplot(f2024) +\n  aes(x = position) +\n  facet_wrap(vars(constructorRef)) +\n  geom_histogram(fill = \"dodgerblue4\", alpha = 0.5, colour = \"black\", linewidth = 0.1)\n```\n\n::: {.cell-output-display}\n![Histograms of driver and constructor performance in F1 2024.](f1_files/figure-html/fig-data-2024-1.png){#fig-data-2024-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Histograms of driver and constructor performance in F1 2024.](f1_files/figure-html/fig-data-2024-2.png){#fig-data-2024-2 width=672}\n:::\n:::\n\n\n\nPoints is simulated as a draw from a Poisson distribution parameterised by the driver performance and constructor performance.\n\n$$\n\\text{points} \\sim \\text{Poisson}(\\text{perf}_{\\text{drv}} + \\text{perf}_{\\text{ctr}})\n$$\n\nDriver performance is simulated as a draw from a normal distribution.\n\n$$\n\\text{perf}_{\\text{drv}} \\sim \\text{Normal}(\\mu_{\\text{drv}}, \\sigma_{\\text{drv}}^2)\n$$\n\nLikewise constructor performance is simulated as a draw from a normal distribution.\n\n$$\n\\text{perf}_{\\text{ctr}} \\sim \\text{Normal}(\\mu_{\\text{ctr}}, \\sigma_{\\text{ctr}}^2)\n$$\n\nWe will therefore have a likelihood function that is the product of the Poisson density of the points for each driver for each race. The number of parameters is very high, as a performance score for each driver and for each constructor.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_likelihood <- function(drv_race_pts, drv_perf, ctr_perf) {\n  ... # whew\n}\n```\n:::\n\n\n\n# Car performance\n\nLet's start simpler, with a view of the car performance. Assume that at least one driver for every constructor maximised the car's performance each weekend. THIS ISN'T TRUE. If Albon had a poor weekend, Sargeant wasn't going to step up, as one of many examples on the grid in 2024. However it is a useful approximation.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nctr_positions <- f2024 |>\n  group_by(round, constructorRef) |>\n  summarise(quali_position = min(quali_position), position = min(position)) |>\n  mutate(\n    # re-rank\n    quali_position = rank(quali_position),\n    position = rank(position)\n  ) |>\n  arrange(round, position)\n\nggplot(ctr_positions) +\n  aes(x = position) +\n  facet_wrap(vars(constructorRef)) +\n  geom_histogram(fill = \"dodgerblue4\", alpha = 0.5, colour = \"black\", linewidth = 0.1)\n```\n\n::: {.cell-output-display}\n![](f1_files/figure-html/simpler-model-1.png){width=672}\n:::\n:::\n\n\n\nA key point here is that we've recalculated positions using only the max driver's position for each constructor, i.e. there are now only 10 finishing positions.\n\nAgain we can simulate the position $p$ as a draw from a Poisson distribution, this time where $\\lambda_\\text{ctr}$ is the performance of the constructor only.\n\n$$\np \\sim \\text{Poisson}(\\lambda_{\\text{ctr}})\n$$\n\nTo keep things simple, let's start with an uninformative prior, a uniform distribution for the performance of the constructors.\n\n$$\n\\lambda_{ctr} \\sim \\text{Uniform}(1, 10)\n$$\n\nThen our likelihood function is much simpler. (We won't actually need this, but I find it useful to write out for the sake of understanding.)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_lik_ctr <- function(ctr_positions, ctr_perfs) {\n  ctrs <- sort(unique(ctr_positions$constructorRef))\n  log_lik <- 1.0\n  for (i in 1:length(ctrs)) {\n    race_posns <- filter(ctr_positions, constructorRef == ctrs[i])$position\n    log_lik <- log_lik + sum(dpois(race_posns, lambda = ctr_perfs[i], log = TRUE))\n  }\n  log_lik\n}\n```\n:::\n\n\n\nLet's throw Stan at this now. Here's our Stan model file.\n\n```\ndata {\n  int<lower=1> n_ctrs;\n  int<lower=1> n_obs;\n  array[n_obs] int<lower=1, upper=10> ctrs;\n  array[n_obs] int<lower=1, upper=10> positions;\n}\nparameters {\n  array[n_ctrs] real<lower=1, upper=10> lambda;\n}\nmodel {\n  lambda ~ uniform(1, 10);\n  positions ~ normal(lambda[ctrs], 1) T[1, 10];\n\n  // the above \"distribution\" syntax is equivalent to:\n  //target += uniform_lpdf(lambda | 1, 10);\n  //target += poisson_lpmf(positions | lambda[ctrs]);\n}\n\n```\n\nAnd here's the R code for interacting with it via CmdStanR. I settled on CmdStanR rather than RStan after hitting too many nameless runtime errors through RStan - see [here](/posts/using-stan-from-r/).\n\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\nlibrary(cmdstanr, quietly = TRUE)\ncheck_cmdstan_toolchain(fix = TRUE, quiet = TRUE)\n\nctrs <- sort(unique(ctr_positions$constructorRef))\nctr_index <- tibble(\n  constructorId = 1:length(ctrs),\n  constructorRef = ctrs,\n)\n\ndo.stan <- function(ctr_positions) {\n  tidy_ctr_posns <- ctr_positions |> merge(ctr_index)\n\n  data_list <- list(\n    n_ctrs = n_distinct(tidy_ctr_posns$constructorId),\n    n_obs = nrow(tidy_ctr_posns),\n    ctrs = tidy_ctr_posns$constructorId,\n    positions = tidy_ctr_posns$position\n  )\n  mod <- cmdstan_model(\"f1.stan\", exe_file = \"f1.bin\")\n  mod$sample(data_list)\n}\n\nfit <- do.stan(ctr_positions)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.1 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.4 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.3 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 1.3 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.3 seconds.\nTotal execution time: 5.3 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  variable    mean  median   sd  mad      q5     q95 rhat ess_bulk ess_tail\n lp__      -442.53 -442.13 2.46 2.26 -447.08 -439.25 1.00     1739     2298\n lambda[1]    6.96    6.96 0.21 0.21    6.63    7.30 1.00     4962     3071\n lambda[2]    5.96    5.96 0.21 0.21    5.61    6.30 1.00     4470     2732\n lambda[3]    2.58    2.59 0.23 0.22    2.21    2.95 1.00     4271     2157\n lambda[4]    6.29    6.29 0.21 0.20    5.96    6.64 1.00     4504     2586\n lambda[5]    1.56    1.56 0.26 0.28    1.14    2.01 1.00     2822     1546\n lambda[6]    4.12    4.12 0.21 0.21    3.77    4.46 1.00     4524     2638\n lambda[7]    6.67    6.68 0.21 0.21    6.33    7.02 1.00     4665     3164\n lambda[8]    3.65    3.65 0.21 0.22    3.30    3.99 1.00     4608     2405\n lambda[9]    8.37    8.36 0.23 0.23    7.99    8.76 1.00     4232     2670\n\n # showing 10 of 11 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n```\n\n\n:::\n:::\n\n\n\nLet's tidy that up though, mapping parameters back to constructor names.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_fit <- function(fit) {\n  df <- fit$draws(\"lambda\", format = \"draws_matrix\") |> as_tibble()\n  colnames(df) <- ctrs\n\n  ggplot(pivot_longer(df, all_of(ctrs))) +\n    aes(x = value) +\n    facet_wrap(vars(name)) +\n    geom_histogram(fill = \"dodgerblue4\", alpha = 0.5, colour = \"black\", linewidth = 0.1, binwidth=0.2)\n}\n\nplot_fit(fit)\n```\n\n::: {.cell-output-display}\n![Posterior samples for constructor performance](f1_files/figure-html/fig-ctr-lambda-posteriors-1.png){#fig-ctr-lambda-posteriors width=672}\n:::\n:::\n\n\n\nThe interesting thing is that this suggests the Red Bull was clearly the third-fastest car. I'm a little suspicious of that, because it claimed a sequence of 1-2s in the first third of the season. Let's take a closer look at that.\n\nThe first thing to check is whether my dumb \"max driver, 10 positions\" model is problematic. Let's look at Red Bull's results.\n\n\n\n::: {#tbl-red-bull-results .cell tbl-cap='Red Bull\\'s results in F1 2024'}\n\n```{.r .cell-code}\nf2024 |>\n  filter(constructorRef == \"red_bull\") |>\n  select(gp, round, driverRef, position) |>\n  pivot_wider(names_from = \"driverRef\", values_from = \"position\") |>\n  arrange(round) |>\n  merge(\n    ctr_positions |> filter(constructorRef == \"red_bull\") |> select(round, position)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   round                        gp perez max_verstappen position\n1      1        Bahrain Grand Prix     2              1        1\n2      2  Saudi Arabian Grand Prix     2              1        1\n3      3     Australian Grand Prix     5             NA       10\n4      4       Japanese Grand Prix     2              1        1\n5      5        Chinese Grand Prix     3              1        1\n6      6          Miami Grand Prix     4              2        2\n7      7 Emilia Romagna Grand Prix     8              1        1\n8      8         Monaco Grand Prix    NA              6       10\n9      9       Canadian Grand Prix    NA              1        9\n10    10        Spanish Grand Prix     8              1        1\n11    11       Austrian Grand Prix     7              5        4\n12    12        British Grand Prix    17              2        1\n13    13      Hungarian Grand Prix     7              5        4\n14    14        Belgian Grand Prix     7              4        3\n15    15          Dutch Grand Prix     6              2        2\n16    16        Italian Grand Prix     8              6        4\n17    17     Azerbaijan Grand Prix    17              5        4\n18    18      Singapore Grand Prix    10              2        2\n19    19  United States Grand Prix     7              3        2\n20    20    Mexico City Grand Prix    17              6        4\n21    21      São Paulo Grand Prix    11              1        1\n22    22      Las Vegas Grand Prix    10              5        3\n23    23          Qatar Grand Prix    NA              1        9\n24    24      Abu Dhabi Grand Prix    NA              6        8\n```\n\n\n:::\n:::\n\n\n\nRound three is clearly a balls-up: how can Pere'z 5th place become the 10th constructor position? Let's work through it again.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf2024 |>\n  group_by(round, constructorRef) |>\n  summarise(position = min(position)) |>\n  mutate(reranked = rank(position)) |>\n  filter(round == 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 4\n# Groups:   round [1]\n   round constructorRef position reranked\n   <dbl> <chr>             <dbl>    <dbl>\n 1     3 alpine               13        7\n 2     3 aston_martin          6        3\n 3     3 ferrari               1        1\n 4     3 haas                  9        5\n 5     3 mclaren               3        2\n 6     3 mercedes             NA        9\n 7     3 rb                    7        4\n 8     3 red_bull             NA       10\n 9     3 sauber               14        8\n10     3 williams             11        6\n```\n\n\n:::\n:::\n\n\n\n`NA` strikes again! Forgot to add the crucial `na.rm` parameter to the min. Right, a do-over.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nctr_positions <- f2024 |>\n  group_by(round, constructorRef) |>\n  summarise(\n    # in the event of a double DNF, assign the last position\n    quali_position = pmin(min(quali_position, na.rm = TRUE), 10),\n    position = pmin(min(position, na.rm = TRUE), 10)\n  ) |>\n  mutate(\n    # re-rank\n    quali_position = rank(quali_position),\n    position = rank(position)\n  ) |>\n  arrange(round, position)\n\nggplot(ctr_positions) +\n  aes(x = position) +\n  facet_wrap(vars(constructorRef)) +\n  geom_histogram(fill = \"dodgerblue4\", alpha = 0.5, colour = \"black\", linewidth = 0.1)\n```\n\n::: {.cell-output-display}\n![Constructor position histograms after fixing NA sorting.](f1_files/figure-html/fig-updated-ctr-positions-1.png){#fig-updated-ctr-positions width=672}\n:::\n:::\n\n\n\nThat looks more like I'd expect. Let's try Stan again.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- do.stan(ctr_positions)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning MCMC with 4 sequential chains...\n\nChain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 1 finished in 1.0 seconds.\nChain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 2 finished in 1.0 seconds.\nChain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 3 finished in 1.0 seconds.\nChain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \nChain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \nChain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \nChain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \nChain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \nChain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \nChain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \nChain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \nChain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \nChain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \nChain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \nChain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \nChain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \nChain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \nChain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \nChain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \nChain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \nChain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \nChain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \nChain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \nChain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \nChain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \nChain 4 finished in 1.0 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 1.0 seconds.\nTotal execution time: 4.3 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\nplot_fit(fit)\n```\n\n::: {.cell-output-display}\n![Posterior samples after fixing NA sorting.](f1_files/figure-html/fig-updated-posterior-samples-1.png){#fig-updated-posterior-samples width=672}\n:::\n:::\n\n\n\nThat is more intuitive: Red Bull is now much closer to McLaren and marginally ahead of Ferrari.",
    "supporting": [
      "f1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}