{
  "hash": "64aabed5712bce26bbd2b487d69c7f7a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Latent F1 team and driver performance: fun with Bayesian models\"\ndate: \"2024-12-27\"\ncategories: [bayesian, r, f1, stan]\nwarning: false\ncode-fold: true\n---\n\n\n\nFor a bit of fun, let's try and model the performance of F1 drivers and constructors in the 2024 season using Bayesian models. The aim is to more to learn about using [Stan](https://mc-stan.org) than determine deep truths about F1, since there's far more to performance than we can easily model.\n\nWe'll vaguely imitate the [f1-metrics](https://f1metrics.wordpress.com) model, which I used to eagerly await after each season. In this model there are latent variables of driver skill and car quality, which predict points/positions. However I never did get hold of the paper for that, and am instead following the amazing [Rasmus Bååth's blog](https://www.sumsar.net/blog/2013/07/modeling-match-results-in-la-liga-part-one/) where he models the latent skill of football teams in La Liga.\n\nI gathered CSVs of race data from the fantastic [Ergast](https://ergast.com/mrd/). The weapon of choice is R and the tidyverse, since nothing else is quite so ergonomic for this type of analysis. You can find the code behind the folds if you want to play along.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(knitr) # this lib is for rendering tables nicely\n\nqualifying <- read_csv(\"data/qualifying.csv\") |> rename(quali_position = position)\nraces <- read_csv(\"data/races.csv\") |>\n  select(raceId, year, round, circuitId, name) |>\n  rename(gp = name)\nresults <- read_csv(\"data/results.csv\") |> select(resultId, raceId, driverId, constructorId, grid, position, points, milliseconds)\nconstructors <- read_csv(\"data/constructors.csv\") |> select(constructorId, constructorRef)\ndrivers <- read_csv(\"data/drivers.csv\") |> select(driverId, driverRef)\ncircuits <- read_csv(\"data/circuits.csv\") |> select(circuitId, circuitRef)\n\nctr_drvs <- tribble(\n  ~constructorRef, ~driverRef,\n  \"alpine\", \"doohan\",\n  \"alpine\", \"gasly\",\n  \"alpine\", \"ocon\",\n  \"aston_martin\", \"alonso\",\n  \"aston_martin\", \"stroll\",\n  \"ferrari\", \"bearman\",\n  \"ferrari\", \"leclerc\",\n  \"ferrari\", \"sainz\",\n  \"haas\", \"bearman\",\n  \"haas\", \"hulkenberg\",\n  \"haas\", \"kevin_magnussen\",\n  \"mclaren\", \"norris\",\n  \"mclaren\", \"piastri\",\n  \"mercedes\", \"hamilton\",\n  \"mercedes\", \"russell\",\n  \"rb\", \"lawson\",\n  \"rb\", \"ricciardo\",\n  \"rb\", \"tsunoda\",\n  \"red_bull\", \"max_verstappen\",\n  \"red_bull\", \"perez\",\n  \"sauber\", \"bottas\",\n  \"sauber\", \"zhou\",\n  \"williams\", \"albon\",\n  \"williams\", \"colapinto\",\n  \"williams\", \"sargeant\",\n)\n\nctr_colours <- tribble(\n  ~constructorRef, ~colour,\n  \"red_bull\", \"#3671c6\",\n  \"mercedes\", \"#26f5d2\",\n  \"ferrari\", \"#e80220\",\n  \"mclaren\", \"#ff8001\",\n  \"aston_martin\", \"#229971\",\n  \"alpine\", \"#F363B9\", # Should be \"#0093cc\" but there's too much blue\n  \"williams\", \"#63c4ff\",\n  \"rb\", \"#6592ff\",\n  \"sauber\", \"#52e252\",\n  \"haas\", \"#b6babd\"\n) |>\n  arrange(constructorRef)\n\ndrv_colours <- ctr_colours |>\n  merge(ctr_drvs) |>\n  group_by(driverRef) |>\n  arrange(constructorRef) |>\n  slice_head(n = 1) |> # alphabetical first for multi-team drivers i.e. Bearman\n  select(driverRef, colour) |>\n  arrange(driverRef)\n\nf1data <- races |>\n  merge(results) |>\n  merge(qualifying) |>\n  merge(constructors) |>\n  merge(drivers) |>\n  merge(circuits) |>\n  select(raceId, gp, year, round, circuitRef, constructorRef, driverRef, q1, q2, q3, quali_position, grid, position) |>\n  mutate(position = ifelse(position == \"\\\\N\", NA, as.numeric(position)))\n```\n:::\n\n\n\nIn the interests of being educational - and because Lord knows I hate editing - I am writing this post as I go, including any blind-alleys and debugging.\n\nLet's start with some visualisations of the data we have.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf2024 <- f1data |> filter(year == 2024)\n\nggplot(f2024) +\n  aes(x = position, fill = driverRef) +\n  facet_wrap(~driverRef) +\n  scale_fill_manual(values = drv_colours$colour) +\n  geom_histogram(alpha = 0.5, colour = \"black\", linewidth = 0.1, binwidth = 1, show.legend = FALSE)\n```\n\n::: {.cell-output-display}\n![Histograms of driver performance in F1 2024.](f1_files/figure-html/fig-data-2024-1.png){#fig-data-2024 width=672}\n:::\n:::\n\n\n\nThe model goes like this. Points are simulated as a draw from a Poisson distribution parameterised by the driver performance and constructor performance.\n\n$$\n\\text{points} \\sim \\text{Poisson}(e^{\\text{perf}_{\\text{drv}} + \\text{perf}_{\\text{ctr}}})\n$$\n\nDriver performance is simulated as a draw from a normal distribution.\n\n$$\n\\text{perf}_{\\text{drv}} \\sim \\text{Normal}(\\mu_{\\text{drv}}, \\sigma_{\\text{drv}}^2)\n$$\n\nLikewise constructor performance is simulated as a draw from a normal distribution.\n\n$$\n\\text{perf}_{\\text{ctr}} \\sim \\text{Normal}(\\mu_{\\text{ctr}}, \\sigma_{\\text{ctr}}^2)\n$$\n\nWe will therefore have a likelihood function that is the product of the Poisson density of the points for each driver for each race. The number of parameters is very high, as a performance score for each driver and for each constructor.\n\n# Constructor performance\n\nLet's start simpler, with a view of just the constructor performance. Assume that at least one driver for every constructor maximised the car's performance each weekend. THIS ISN'T TRUE. If Albon had a poor weekend, Sargeant wasn't going to step up, as one of many examples on the grid in 2024. However it is a useful approximation that let's us analyse just the constructor performance.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nctr_positions <- f2024 |>\n  group_by(round, constructorRef) |>\n  summarise(quali_position = min(quali_position), position = min(position)) |>\n  mutate(\n    # re-rank\n    quali_position = rank(quali_position),\n    position = rank(position)\n  ) |>\n  arrange(round, position)\n\nggplot(ctr_positions) +\n  aes(x = position, fill = constructorRef) +\n  facet_wrap(~constructorRef) +\n  scale_fill_manual(values = ctr_colours$colour) +\n  geom_histogram(alpha = 0.5, colour = \"black\", linewidth = 0.1, binwidth = 1, show.legend = FALSE)\n```\n\n::: {.cell-output-display}\n![Histogram of re-ranked constructor results in F1 2024.](f1_files/figure-html/fig-simpler-model-1.png){#fig-simpler-model width=672}\n:::\n:::\n\n\n\nA key point here is that we've recalculated positions using only the max driver's position for each constructor, i.e. there are now only 10 finishing positions.\n\nAgain we can simulate the position $p$ as a draw from a Poisson distribution, this time where $\\lambda_\\text{ctr}$ is the performance of the constructor only.\n\n$$\np \\sim \\text{Poisson}(\\lambda_{\\text{ctr}})\n$$\n\nTo keep things simple, let's start with an uninformative prior, a uniform distribution for the performance of the constructors.\n\n$$\n\\lambda_{ctr} \\sim \\text{Uniform}(1, 10)\n$$\n\nThen our likelihood function is much simpler. (We won't actually need this, but I find it useful to write out for the sake of understanding.)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog_lik_ctr <- function(ctr_positions, ctr_perfs) {\n  ctrs <- sort(unique(ctr_positions$constructorRef))\n  log_lik <- 1.0\n  for (i in 1:length(ctrs)) {\n    race_posns <- filter(ctr_positions, constructorRef == ctrs[i])$position\n    log_lik <- log_lik + sum(dpois(race_posns, lambda = ctr_perfs[i], log = TRUE))\n  }\n  log_lik\n}\n```\n:::\n\n\n\nLet's throw Stan at this now. Here's our Stan model file.\n\n```\ndata {\n  int<lower=1> n_ctrs;\n  int<lower=1> n_obs;\n  array[n_obs] int<lower=1, upper=10> ctrs;\n  array[n_obs] int<lower=1, upper=10> positions;\n}\nparameters {\n  array[n_ctrs] real<lower=1, upper=10> lambda;\n}\nmodel {\n  lambda ~ uniform(1, 10);\n  positions ~ poisson(lambda[ctrs]) T[1, 10];\n\n  // the above \"distribution\" syntax is equivalent to:\n  //target += uniform_lpdf(lambda | 1, 10);\n  //target += poisson_lpmf(positions | lambda[ctrs]);\n}\n\n```\n\nBelow the fold is the R code for interacting with it via CmdStanR. I settled on CmdStanR rather than RStan after hitting too many nameless runtime errors through RStan - see [here](/posts/using-stan-from-r/).\n\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code}\nlibrary(cmdstanr, quietly = TRUE)\ncheck_cmdstan_toolchain(fix = TRUE, quiet = TRUE)\n\nctrs <- sort(unique(ctr_positions$constructorRef))\nctr_index <- tibble(\n  constructorId = 1:length(ctrs),\n  constructorRef = ctrs,\n)\n\nmake_data_list <- function(ctr_positions) {\n  tidy_ctr_posns <- ctr_positions |> merge(ctr_index)\n\n  data_list <- list(\n    n_ctrs = n_distinct(tidy_ctr_posns$constructorId),\n    n_obs = nrow(tidy_ctr_posns),\n    ctrs = tidy_ctr_posns$constructorId,\n    positions = tidy_ctr_posns$position\n  )\n}\n\nrun_stan <- function(data_list, model_file = \"f1.stan\") {\n  mod <- cmdstan_model(model_file, exe_file = str_c(model_file, \".bin\"))\n  mod$sample(data_list, seed = 42, show_messages = FALSE)\n}\n\nfit <- run_stan(make_data_list(ctr_positions))\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  variable    mean  median   sd  mad      q5     q95 rhat ess_bulk ess_tail\n lp__      1066.12 1066.51 2.55 2.39 1061.39 1069.56 1.00     1354     1292\n lambda[1]    7.99    7.97 0.78 0.83    6.74    9.34 1.00     2800     1333\n lambda[2]    6.34    6.31 0.60 0.60    5.42    7.40 1.00     3941     2479\n lambda[3]    2.53    2.52 0.36 0.35    1.97    3.14 1.00     4395     2641\n lambda[4]    6.86    6.84 0.67 0.67    5.82    8.00 1.00     3546     1968\n lambda[5]    1.70    1.68 0.30 0.30    1.24    2.20 1.00     3741     1634\n lambda[6]    4.12    4.11 0.43 0.44    3.42    4.86 1.00     4405     3065\n lambda[7]    7.48    7.43 0.77 0.78    6.28    8.79 1.00     1509      649\n lambda[8]    3.62    3.61 0.42 0.41    2.96    4.33 1.00     4388     3150\n lambda[9]    9.49    9.60 0.43 0.38    8.65    9.97 1.00     2975     1581\n\n # showing 10 of 11 rows (change via 'max_rows' argument or 'cmdstanr_max_rows' option)\n```\n\n\n:::\n:::\n\n\n\nLet's tidy that up though, mapping parameters back to constructor names.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_posterior <- function(fit) {\n  df <- fit$draws(\"lambda\", format = \"draws_matrix\") |> as_tibble()\n  colnames(df) <- ctrs\n  df |>\n    pivot_longer(\n      all_of(ctrs),\n      names_to = \"constructorRef\", values_to = \"position\"\n    ) |>\n    mutate(position = as.double(position))\n}\n\nplot_posterior <- function(fit) {\n  means <- sample_posterior(fit) |>\n    group_by(constructorRef) |>\n    summarise(mu = mean(position))\n  ggplot(sample_posterior(fit)) +\n    aes(x = position, fill = constructorRef) +\n    scale_fill_manual(values = ctr_colours$colour) +\n    geom_density(alpha = 0.5, colour = \"black\", linewidth = 0.1)\n}\n\nplot_posterior(fit)\n```\n\n::: {.cell-output-display}\n![Posterior samples for constructor performance](f1_files/figure-html/fig-ctr-lambda-posteriors-1.png){#fig-ctr-lambda-posteriors width=672}\n:::\n:::\n\n\n\nOn this plot lower x-values are better.\n\nThe interesting thing is that this suggests the Red Bull was clearly the third-fastest car. I'm a little suspicious of that, because it claimed a sequence of 1-2s in the first third of the season. Let's take a closer look at that.\n\nThe first thing to check is whether my dumb \"max driver, 10 positions\" model is problematic. Let's look at Red Bull's results.\n\n\n\n::: {#tbl-red-bull-results .cell tbl-cap='Red Bull\\'s results in F1 2024'}\n\n```{.r .cell-code}\nf2024 |>\n  filter(constructorRef == \"red_bull\") |>\n  select(gp, round, driverRef, position) |>\n  pivot_wider(names_from = \"driverRef\", values_from = \"position\") |>\n  arrange(round) |>\n  merge(\n    ctr_positions |> filter(constructorRef == \"red_bull\") |> select(round, position)\n  ) |>\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| round|gp                        | perez| max_verstappen| position|\n|-----:|:-------------------------|-----:|--------------:|--------:|\n|     1|Bahrain Grand Prix        |     2|              1|        1|\n|     2|Saudi Arabian Grand Prix  |     2|              1|        1|\n|     3|Australian Grand Prix     |     5|             NA|       10|\n|     4|Japanese Grand Prix       |     2|              1|        1|\n|     5|Chinese Grand Prix        |     3|              1|        1|\n|     6|Miami Grand Prix          |     4|              2|        2|\n|     7|Emilia Romagna Grand Prix |     8|              1|        1|\n|     8|Monaco Grand Prix         |    NA|              6|       10|\n|     9|Canadian Grand Prix       |    NA|              1|        9|\n|    10|Spanish Grand Prix        |     8|              1|        1|\n|    11|Austrian Grand Prix       |     7|              5|        4|\n|    12|British Grand Prix        |    17|              2|        1|\n|    13|Hungarian Grand Prix      |     7|              5|        4|\n|    14|Belgian Grand Prix        |     7|              4|        3|\n|    15|Dutch Grand Prix          |     6|              2|        2|\n|    16|Italian Grand Prix        |     8|              6|        4|\n|    17|Azerbaijan Grand Prix     |    17|              5|        4|\n|    18|Singapore Grand Prix      |    10|              2|        2|\n|    19|United States Grand Prix  |     7|              3|        2|\n|    20|Mexico City Grand Prix    |    17|              6|        4|\n|    21|São Paulo Grand Prix      |    11|              1|        1|\n|    22|Las Vegas Grand Prix      |    10|              5|        3|\n|    23|Qatar Grand Prix          |    NA|              1|        9|\n|    24|Abu Dhabi Grand Prix      |    NA|              6|        8|\n\n\n:::\n:::\n\n\n\nRound three is clearly a mistake: how can Perez' 5th place become the 10th constructor position? Let's work through it again.\n\n\n\n::: {#tbl-round-3-results .cell tbl-cap='Round 3 results.'}\n\n```{.r .cell-code}\nf2024 |>\n  group_by(round, constructorRef) |>\n  summarise(position = min(position)) |>\n  mutate(reranked = rank(position)) |>\n  filter(round == 3) |>\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| round|constructorRef | position| reranked|\n|-----:|:--------------|--------:|--------:|\n|     3|alpine         |       13|        7|\n|     3|aston_martin   |        6|        3|\n|     3|ferrari        |        1|        1|\n|     3|haas           |        9|        5|\n|     3|mclaren        |        3|        2|\n|     3|mercedes       |       NA|        9|\n|     3|rb             |        7|        4|\n|     3|red_bull       |       NA|       10|\n|     3|sauber         |       14|        8|\n|     3|williams       |       11|        6|\n\n\n:::\n:::\n\n\n\n`NA` strikes again! Forgot to add the crucial `na.rm` parameter to the min. Right, a do-over.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nctr_positions <- f2024 |>\n  group_by(round, constructorRef) |>\n  summarise(\n    # in the event of a double DNF, assign the last position\n    quali_position = pmin(min(quali_position, na.rm = TRUE), 10),\n    position = pmin(min(position, na.rm = TRUE), 10)\n  ) |>\n  mutate(\n    # re-rank\n    quali_position = rank(quali_position),\n    position = rank(position)\n  ) |>\n  arrange(round, position)\n\nggplot(ctr_positions) +\n  aes(x = position, fill = constructorRef) +\n  facet_wrap(~constructorRef) +\n  scale_fill_manual(values = ctr_colours$colour) +\n  geom_histogram(alpha = 0.5, colour = \"black\", linewidth = 0.1, binwidth = 1, show.legend = FALSE)\n```\n\n::: {.cell-output-display}\n![Constructor position histograms after fixing NA sorting.](f1_files/figure-html/fig-updated-ctr-positions-1.png){#fig-updated-ctr-positions width=672}\n:::\n:::\n\n\n\nThat looks more like I'd expect. Let's try Stan again.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- run_stan(make_data_list(ctr_positions))\nplot_posterior(fit)\n```\n\n::: {.cell-output-display}\n![Posterior samples after fixing NA sorting.](f1_files/figure-html/fig-updated-posterior-samples-1.png){#fig-updated-posterior-samples width=672}\n:::\n:::\n\n\n\nThat is more intuitive: Red Bull is now much closer to McLaren and marginally ahead of Ferrari (despite coming third in the constructor's championship). This tells us that yes, Verstappen probably would have won the driver's championship in a McLaren - but contrary to claims, not in a Ferrari, since it wasn't faster than the Red Bull overall.\n\nThe three teams that are on top of each other are: Alpine, Haas, and RB. You can also just about discern that the model is less sure about the top teams, since their posteriors are slightly wider.\n\nThere's a lot we can improve about this model. The most obvious is that our priors for constructor performance are uniformative, and so our posteriors basically just reflect the data. Can we add some useful information to inform the model?\n\n## More informative priors\n\nWhat makes some constructors better than others? ~~Adrian Newey~~ Money. Let's reflect this in our priors.\n\n$$\n\\lambda_{\\text{ctr}} \\sim \\text{Normal}(\\text{budget}_\\text{ctr}, \\sigma)\n$$\n\n### Budget data\n\nThis is a bit of a secret, so we have to estimate. We do know that the budget cap is 135M USD and it's unlikely that anyone is operating below the cap. We also know that driver and top executive salaries are exempt from the cap. The top teams are spending about 100M USD on their drivers, and prior to the budget cap's implementation likely invested in facilities that they can use for free (like wind tunnels).\n\nWith that in mind, I asked GPT-4o to search the web and estimate budgets for the teams. It came back with these results, which I sanity checked against [this Blackbook Motorsport](https://www.blackbookmotorsport.com/content/f1-team-finances-2023-financial-results-revenue-profit-budget-cap/) article.\n\n\n\n::: {#tbl-ctr-budgets .cell tbl-cap='Constructor budget estimates (USD millions)'}\n\n```{.r .cell-code}\nbudgets <- tribble(\n  ~constructorRef, ~budget,\n  \"red_bull\", 400,\n  \"mercedes\", 400,\n  \"ferrari\", 400,\n  \"mclaren\", 250,\n  \"aston_martin\", 250,\n  \"alpine\", 200,\n  \"rb\", 150,\n  \"haas\", 150,\n  \"williams\", 150,\n  \"sauber\", 150\n) |>\n  mutate(\n    norm_budget = 1 - budget / max(budget)\n  )\nkable(select(budgets, -norm_budget))\n```\n\n::: {.cell-output-display}\n\n\n|constructorRef | budget|\n|:--------------|------:|\n|red_bull       |    400|\n|mercedes       |    400|\n|ferrari        |    400|\n|mclaren        |    250|\n|aston_martin   |    250|\n|alpine         |    200|\n|rb             |    150|\n|haas           |    150|\n|williams       |    150|\n|sauber         |    150|\n\n\n:::\n:::\n\n\n\nLet's update our model and run Stan again.\n\n```\ndata {\n  int<lower=1> n_ctrs;\n  int<lower=1> n_obs;\n  array[n_ctrs] int<lower=1, upper=10> prior_mus;\n  real<lower=0> prior_sd;\n  array[n_obs] int<lower=1, upper=10> ctrs;\n  array[n_obs] int<lower=1, upper=10> positions;\n}\nparameters {\n  array[n_ctrs] real<lower=1, upper=10> lambda;\n}\nmodel {\n  lambda ~ normal(prior_mus, prior_sd);\n  positions ~ poisson(lambda[ctrs]) T[1, 10];\n}\n\n```\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_list_b <- make_data_list(ctr_positions)\ndata_list_b$prior_mus <- 1 + 10 * arrange(budgets, constructorRef)$norm_budget\ndata_list_b$prior_sd <- 1.5\nfit.b <- run_stan(data_list_b, model_file = \"f1.b.stan\")\n\nplot_posterior(fit.b)\n```\n\n::: {.cell-output-display}\n![Posterior samples from the model with budget-based priors.](f1_files/figure-html/fig-run-stan-b-1.png){#fig-run-stan-b width=672}\n:::\n:::\n\n\n\nThis hasn't made much difference. McLaren has eased back towards Red Bull because their budget is smaller. You could say they did a lot better than Red Bull relative to their budget.\n\n\n\n::: {#tbl-mu-sig-fit-b .cell tbl-cap='Mean and SD from posterior sample.'}\n\n```{.r .cell-code}\nsp <- sample_posterior(fit.b)\nsp |>\n  group_by(constructorRef) |>\n  summarise(mu = mean(position), sigma = sd(position)) |>\n  arrange(mu) |>\n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|constructorRef |   mu| sigma|\n|:--------------|----:|-----:|\n|mclaren        | 2.06|  0.33|\n|red_bull       | 2.07|  0.32|\n|ferrari        | 2.40|  0.32|\n|mercedes       | 3.02|  0.36|\n|aston_martin   | 6.42|  0.56|\n|alpine         | 7.80|  0.66|\n|haas           | 8.00|  0.67|\n|rb             | 8.07|  0.67|\n|williams       | 8.82|  0.63|\n|sauber         | 9.12|  0.56|\n\n\n:::\n:::\n\n\n\nThis model suggests there's very little nothing in it between Red Bull and McLaren, though the posterior distribution is wider for the top three teams than the others so there is more uncertainty.\n\nWas budget a bad choice for the prior? Not necessarily: this model of constructor performance incorporates an important factor that isn't clear from the results, but which should affect an objective assessment of which teams are better. Or to put it another way, if I were Max Verstappen I'd still rather be driving the Red Bull than the McLaren next year, because Red Bull's budget suggests a more capable team overall. (Not to mention the increased wind tunnel time that third place in the constructors' gets relative to the winner.)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_posterior_with_prior <- function(ctrs, prior_mus, prior_sd, fit) {\n  s_post <- sample_posterior(fit) |> mutate(sample = \"posterior\")\n\n  ctr_index <- tibble(constructorRef = ctrs, constructorId = 1:length(ctrs))\n\n  s_prior <- prior_mus |>\n    lapply(\\(mu) rnorm(100000, mu, prior_sd)) |>\n    lapply(as_tibble) |>\n    imap(\\(t, i) mutate(t, constructorId = i, sample = \"prior\")) |>\n    bind_rows() |>\n    rename(position = value) |>\n    merge(ctr_index)\n\n  df <- bind_rows(s_prior, s_post)\n\n  ggplot(df) +\n    aes(x = position, fill = sample) +\n    facet_wrap(~constructorRef) +\n    geom_density(alpha = 0.5, linewidth = 0.1) +\n    scale_x_continuous(breaks = seq(1, 10, by = 2), limits = c(1, 10)) +\n    scale_fill_manual(values = c(\"dodgerblue1\", \"dodgerblue4\"))\n}\n\nplot_posterior_with_prior(ctrs, data_list_b$prior_mus, data_list_b$prior_sd, fit.b)\n```\n\n::: {.cell-output-display}\n![Comparison of prior and posterior samples.](f1_files/figure-html/fig-plot-with-priors-1.png){#fig-plot-with-priors width=672}\n:::\n:::\n\n\n\nPlotting the priors and posteriors together shows how McLaren over-performed and Mercedes continued to underperform.\n\n### Past performance\n\nAnother, very easy way to set the priors is to consider the constructors' performance over the previous seasons with the same regulations, in this case 2022 and 2023 (the ground-effect era). This is really easy to do - we would just take a weighted mean of the constructors' finishing positions as mu for our priors, and perhaps set the variance proportional to the difference. Not particularly innovative or interesting though, so let's skip it.\n\n### Car-limited circuits\n\nLong-time F1 fans will know that at some tracks, the cars almost always finish in pairs, e.g. both Ferraris, then both Mercedes, and so on. Somehow at these circuits driver skill makes little difference; we could say the circuits are car-limited rather than driver-limited. That's no fun to watch, but I wonder if it's useful for establishing car performance?\n\nLet's look back at historic race results to see if some circuits are more likely to finish in two-by-two order. We can score this by the median difference in position between finishing drivers.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncircuits2024 <- races |>\n  merge(circuits) |>\n  filter(year == 2024) |>\n  select(circuitRef)\n\nposition_gaps <- f1data |>\n  filter(year > 2014) |> # hybrid era onwards, to try and keep it relevant to modern F1 car sizes\n  merge(circuits2024) |> # circuits from 2024 only\n  select(year, round, circuitRef, constructorRef, driverRef, position) |>\n  filter(position != \"\\\\N\") |> # ignore DNFs\n  mutate(position = as.integer(position)) |>\n  group_by(year, round, circuitRef, constructorRef) |>\n  filter(n() == 2) |> # must be a double finish\n  summarise(gap = max(position) - min(position), max_position = max(position)) |>\n  group_by(circuitRef) |>\n  mutate(median_gap = median(gap))\n\nggplot(position_gaps) +\n  aes(x = gap) +\n  facet_wrap(vars(circuitRef)) +\n  geom_histogram(fill = \"dodgerblue1\", alpha = 0.5, colour = \"black\", linewidth = 0.1, binwidth = 1) +\n  geom_vline(mapping = aes(xintercept = median_gap), colour = \"dodgerblue4\")\n```\n\n::: {.cell-output-display}\n![Distribution of finishing position gaps between teammates by circuit, with median line.](f1_files/figure-html/fig-position-gaps-1.png){#fig-position-gaps width=672}\n:::\n:::\n\n\n\nPerhaps unsurprisingly given that F1 isn't a spec series, the gap between drivers of the same car is usually very low. I went back and forth on whether to discard cars that finished outside the top ten points-paying positions, as this often includes cars that were retired to save expense or were wounded but finished the race well below their potential for the sake of data gathering. In the end I kept them in because we need two-car finishes to calculate the statistics and setting a threshold would mean re-coding all the finish positions.\n\nIt turns out to make little difference anyway. The race with the highest probability of teammates finishing in consecutive positions is Suzuka, whether or not you apply a threshold.\n\n\n\n::: {#tbl-position-gaps-medians .cell tbl-cap='Circuits with highest probability of having teammates finishing together.'}\n\n```{.r .cell-code}\nrounds2024 <- races |>\n  filter(year == 2024) |>\n  merge(circuits) |>\n  select(circuitRef, round) |>\n  rename(round2024 = round)\n\np_gap_1 <- position_gaps |>\n  count(circuitRef, gap) |>\n  group_by(circuitRef) |>\n  mutate(p_gap = n / sum(n)) |>\n  filter(gap == 1) |>\n  ungroup() |>\n  merge(rounds2024)\n\np_gap_1 |>\n  slice_max(p_gap, n = 10) |>\n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|circuitRef  | gap|  n| p_gap| round2024|\n|:-----------|---:|--:|-----:|---------:|\n|suzuka      |   1| 29|  0.48|         4|\n|albert_park |   1| 19|  0.41|         3|\n|rodriguez   |   1| 26|  0.39|        20|\n|jeddah      |   1| 10|  0.38|         2|\n|yas_marina  |   1| 29|  0.36|        24|\n|imola       |   1| 10|  0.33|         7|\n|hungaroring |   1| 26|  0.32|        13|\n|shanghai    |   1| 15|  0.31|         5|\n|bahrain     |   1| 25|  0.30|         1|\n|interlagos  |   1| 19|  0.30|        21|\n\n\n:::\n:::\n\n\n\nHow did the cars line up at Suzuka in 2024, noting that this was round 4 of a 24-round championship?\n\n\n\n::: {#tbl-suzuka-2024 .cell tbl-cap='Results for Suzuka 2024 (two-car finishes only)'}\n\n```{.r .cell-code}\nsuzuka2024 <- f1data |>\n  filter(year == 2024) |>\n  filter(circuitRef == \"suzuka\") |>\n  select(year, round, circuitRef, constructorRef, driverRef, quali_position, position)\n\nsuzuka2024 |>\n  drop_na() |>\n  group_by(constructorRef) |>\n  filter(n() == 2) |>\n  arrange(position) |>\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| year| round|circuitRef |constructorRef |driverRef       | quali_position| position|\n|----:|-----:|:----------|:--------------|:---------------|--------------:|--------:|\n| 2024|     4|suzuka     |red_bull       |max_verstappen  |              1|        1|\n| 2024|     4|suzuka     |red_bull       |perez           |              2|        2|\n| 2024|     4|suzuka     |ferrari        |sainz           |              4|        3|\n| 2024|     4|suzuka     |ferrari        |leclerc         |              8|        4|\n| 2024|     4|suzuka     |mclaren        |norris          |              3|        5|\n| 2024|     4|suzuka     |aston_martin   |alonso          |              5|        6|\n| 2024|     4|suzuka     |mercedes       |russell         |              9|        7|\n| 2024|     4|suzuka     |mclaren        |piastri         |              6|        8|\n| 2024|     4|suzuka     |mercedes       |hamilton        |              7|        9|\n| 2024|     4|suzuka     |haas           |hulkenberg      |             12|       11|\n| 2024|     4|suzuka     |aston_martin   |stroll          |             16|       12|\n| 2024|     4|suzuka     |haas           |kevin_magnussen |             18|       13|\n| 2024|     4|suzuka     |alpine         |ocon            |             15|       15|\n| 2024|     4|suzuka     |alpine         |gasly           |             17|       16|\n\n\n:::\n:::\n\n\n\nThe cars are quite well in order here, if you ignore the gulf between Alonso and Stroll. It looks like Suzuka is really a car-limited track. Incidentally, this would suggest that in round 4, McLaren and Mercedes were quite evenly matched.\n\n#### Counter-arguments\n\nAre we _sure_ Suzuka is a car-limited track?\n\n##### Suzuka is a track \"drivers love\"! Surely it's a more skill-dependent track?\n\nI would have expected so! Suzuka is described as a technical track, with minimal room for error. Perhaps there aren't as many potential lines that a driver could take to distinguish themselves. It's also a good track for overtaking, so any driver that does qualify out of position is able to recover. Or perhaps the reason drivers love it is because they get to drive their cars on the limit: the limit of the car's performance.\n\nEither way, statistically drivers are more likely to end up in pairs in Suzuka than anywhere else.\n\n##### Suzuka was an early round. Perhaps car performance converges over the season?\n\nOn the one hand we'd expect to see cars start at different levels but converge throughout the season, as the teams spot innovations on other cars that they can copy. Or secret design documents that they can copy, ahem. On the other hand, constructors in a tight battle would be motivated to develop their cars further - for example in 2022 when Red Bull overhauled an early Ferrari advantage.\n\nAs it happens, historically Suzuka has been mid-to-late season, which suggests that being an early round in 2024 isn't the reason for being car-limited.\n\n\n\n::: {#tbl-suzuka-round-numbers .cell tbl-cap='Suzuka\\'s placement in each season'}\n\n```{.r .cell-code}\nraces |>\n  filter(year >= 2014) |>\n  group_by(year) |>\n  mutate(n_rounds = n_distinct(round)) |>\n  ungroup() |>\n  merge(circuits) |>\n  filter(circuitRef == \"suzuka\") |>\n  select(year, round, n_rounds) |>\n  arrange(year, round) |>\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| year| round| n_rounds|\n|----:|-----:|--------:|\n| 2014|    15|       19|\n| 2015|    14|       19|\n| 2016|    17|       21|\n| 2017|    16|       20|\n| 2018|    17|       21|\n| 2019|    17|       21|\n| 2022|    18|       22|\n| 2023|    16|       22|\n| 2024|     4|       24|\n\n\n:::\n:::\n\n\n\nHowever the fact that it was an early round in 2024 **does** mean that car performance will have changed over the season. Suzuka can only ever be a point-in-time assessment.\n\n##### Are we sure that consecutive finishes aren't indicative of similar driver skill levels?\n\nThe top teams can also hire the best drivers, is it not possible that we're still seeing the drivers finishing in skill order? I.e. it's actually driver-limited, but the drivers happen to be mostly paired with similarly-fast drivers. Alonso and Stroll being the clear exception in the 2024 race results.\n\nOn the other hand, between 2023 and 2024 there were no line-up changes among the top 5 teams, so we can easily compare across the two years.\n\n\n\n::: {#tbl-suzuka-2023 .cell tbl-cap='Results for Suzuka 2024 (two-car finishes only)'}\n\n```{.r .cell-code}\nsuzuka2023 <- f1data |>\n  filter(year == 2023) |>\n  filter(circuitRef == \"suzuka\") |>\n  select(year, round, circuitRef, constructorRef, driverRef, quali_position, position)\n\nsuzuka2023 |>\n  drop_na() |>\n  group_by(constructorRef) |>\n  filter(n() == 2) |>\n  arrange(position) |>\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| year| round|circuitRef |constructorRef |driverRef       | quali_position| position|\n|----:|-----:|:----------|:--------------|:---------------|--------------:|--------:|\n| 2023|    16|suzuka     |mclaren        |norris          |              3|        2|\n| 2023|    16|suzuka     |mclaren        |piastri         |              2|        3|\n| 2023|    16|suzuka     |ferrari        |leclerc         |              4|        4|\n| 2023|    16|suzuka     |mercedes       |hamilton        |              7|        5|\n| 2023|    16|suzuka     |ferrari        |sainz           |              6|        6|\n| 2023|    16|suzuka     |mercedes       |russell         |              8|        7|\n| 2023|    16|suzuka     |alpine         |ocon            |             14|        9|\n| 2023|    16|suzuka     |alpine         |gasly           |             12|       10|\n| 2023|    16|suzuka     |alphatauri     |lawson          |             11|       11|\n| 2023|    16|suzuka     |alphatauri     |tsunoda         |              9|       12|\n| 2023|    16|suzuka     |haas           |hulkenberg      |             18|       14|\n| 2023|    16|suzuka     |haas           |kevin_magnussen |             15|       15|\n\n\n:::\n:::\n\n\n\nThe order of constructors is very different, despite all drivers being the same except for Alpha Tauri/RB. Just for fun, here's a side-by-side comparison for each driver for 2023 and 2024.\n\n\n\n::: {#tbl-drivers-suzuka-2023-2024 .cell tbl-cap='Drivers\\' results for Suzuka in 2023 and 2024'}\n\n```{.r .cell-code}\ns24 <- suzuka2024 |>\n  select(constructorRef, driverRef, position) |>\n  rename(position2024 = position)\n\ns23 <- suzuka2023 |>\n  # correct to the new names for joining\n  # (yes I could have used constructorId, but opaque IDs are so tedious to handle)\n  mutate(constructorRef = ifelse(constructorRef == \"alphatauri\", \"rb\", constructorRef)) |>\n  mutate(constructorRef = ifelse(constructorRef == \"alfa\", \"sauber\", constructorRef)) |>\n  select(constructorRef, driverRef, position) |>\n  rename(position2023 = position)\n\nmerge(s23, s24, all = TRUE) |>\n  arrange(position2023) |>\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|constructorRef |driverRef       | position2023| position2024|\n|:--------------|:---------------|------------:|------------:|\n|red_bull       |max_verstappen  |            1|            1|\n|mclaren        |norris          |            2|            5|\n|mclaren        |piastri         |            3|            8|\n|ferrari        |leclerc         |            4|            4|\n|mercedes       |hamilton        |            5|            9|\n|ferrari        |sainz           |            6|            3|\n|mercedes       |russell         |            7|            7|\n|aston_martin   |alonso          |            8|            6|\n|alpine         |ocon            |            9|           15|\n|alpine         |gasly           |           10|           16|\n|rb             |lawson          |           11|           NA|\n|rb             |tsunoda         |           12|           10|\n|sauber         |zhou            |           13|           NA|\n|haas           |hulkenberg      |           14|           11|\n|haas           |kevin_magnussen |           15|           13|\n|aston_martin   |stroll          |           NA|           12|\n|rb             |ricciardo       |           NA|           NA|\n|red_bull       |perez           |           NA|            2|\n|sauber         |bottas          |           NA|           14|\n|williams       |albon           |           NA|           NA|\n|williams       |sargeant        |           NA|           17|\n\n\n:::\n:::\n\n\n\n##### Don't certain tracks favour certain cars (e.g. due to having fewer slow corners)?\n\nThis is a valid objection. We can only really say that this reflects car performance at tracks like Suzuka. Suzuka is a high-speed, high-downforce track with more high-speed than low-speed corners. You can kind of tell by looking that only corners 2, 9, 11, and 14 are slow.\n\n![Suzuka Circuit Layout](./suzuka.jpg)\n\n_Data and image from [the F1 Formbook](https://thef1formbook.wordpress.com/2016/10/06/suzuka-circuit-guide-2016/)._\n\nSo perhaps another way of looking at it is that low-speed corners are where drivers make the most difference. That aligns with the excellent [recent analysis by Mark Hughes](https://www.the-race.com/formula-1/ferrari-f1-car-traits-lewis-hamilton-driving-style/) where he explains how drivers like Leclerc and Hamilton make up their time in slow corners.\n\nNaturally certain cars will also be better at slow corners, and that's not represented at Suzuka. We might be able to gain a better understanding with sector times, but sadly I don't have this data.\n\n### Suzuka-based priors\n\nAt this point I'm convinced enough that Suzuka is a useful indicator of relative car performance to be a prior, so let's take the position of each team's fastest car round Suzuka as constructor performance priors. Luckily there weren't any double-DNFs - at least one car from each team finished - so every team is represented.\n\nThe Stan model is the same, we're just injecting different prior mus and SDs.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuzuka_positions <- suzuka2024 |>\n  drop_na() |>\n  group_by(constructorRef) |>\n  summarise(position = min(position)) |>\n  mutate(position = rank(position)) |>\n  arrange(constructorRef)\n\ndata_list_suzuka <- make_data_list(ctr_positions)\ndata_list_suzuka$prior_mus <- suzuka_positions$position\ndata_list_suzuka$prior_sd <- 1\n\nfit_suzuka <- run_stan(data_list_suzuka, \"f1.b.stan\")\n\nplot_posterior(fit_suzuka)\n```\n\n::: {.cell-output-display}\n![Posterior samples for the Suzuka-position priors.](f1_files/figure-html/fig-suzuka-posterior-1.png){#fig-suzuka-posterior width=672}\n:::\n:::\n\n\n\nIt's not dramatically different. It shouldn't be, the model and data are the same and the priors are very similar to the budget-based priors - the fun was in figuring out that Suzuka is car-limited.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_posterior_with_prior(ctrs, data_list_suzuka$prior_mus, data_list_suzuka$prior_sd, fit_suzuka)\n```\n\n::: {.cell-output-display}\n![Posterior samples alongside the Suzuka-position priors.](f1_files/figure-html/fig-suzuka-posterior-with-prior-1.png){#fig-suzuka-posterior-with-prior width=672}\n:::\n:::\n\n\n\nMost teams didn't move far from their priors. I'd draw similar conclusions to before: the McLaren was fastest, Red Bull was a close second, and Ferrari were not far behind.\n\n\n\n::: {#tbl-mu-sig-fit-suzuka .cell tbl-cap='Mean and SD from posterior sample, with Suzuka priors.'}\n\n```{.r .cell-code}\nsp <- sample_posterior(fit_suzuka)\nsp |>\n  group_by(constructorRef) |>\n  summarise(mu = mean(position), sigma = sd(position)) |>\n  arrange(mu) |>\n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|constructorRef |   mu| sigma|\n|:--------------|----:|-----:|\n|red_bull       | 2.01|  0.31|\n|mclaren        | 2.05|  0.32|\n|ferrari        | 2.42|  0.32|\n|mercedes       | 3.39|  0.39|\n|aston_martin   | 6.07|  0.49|\n|rb             | 7.47|  0.56|\n|haas           | 7.77|  0.58|\n|alpine         | 8.55|  0.64|\n|sauber         | 9.08|  0.52|\n|williams       | 9.39|  0.44|\n\n\n:::\n:::\n\n\n\n# Reintroducing driver skill\n\nSimple model achieved, let's push on to something more complex i.e. the originally described model. Here it is:\n\n```\ndata {\n  int<lower=1> n_ctrs;\n  int<lower=1> n_drvs;\n  int<lower=1> n_obs;\n  array[n_ctrs] real ctr_mus;\n  real<lower=0> ctr_sd;\n  array[n_obs] int<lower=1, upper=20> positions;\n  array[n_obs, 2] int position_indices;\n}\nparameters {\n  vector[n_ctrs] lambda_ctrs_raw;\n  vector[n_drvs] lambda_drvs_raw;\n}\ntransformed parameters {\n  vector[n_ctrs] lambda_ctrs;\n  vector[n_drvs] lambda_drvs;\n  \n  // Apply constraints to ensure identifiability\n  lambda_ctrs = log(20) * inv_logit(lambda_ctrs_raw);\n  lambda_drvs = log(20) * inv_logit(lambda_drvs_raw);\n}\nmodel {\n  lambda_ctrs_raw ~ normal(ctr_mus, ctr_sd);\n  lambda_drvs_raw ~ std_normal();\n  \n  for (k in 1 : n_obs) {\n    int i = position_indices[k, 1];\n    int j = position_indices[k, 2];\n    positions[k] ~ poisson(exp(lambda_ctrs[i] + lambda_drvs[j]));\n  }\n}\n\n```\n\nThere is a crucial change. To ensure the model is identifiable, the raw skill parameters are constrained to [0, 1] with an inverse logistic transform. The transformed parameters are then summed and exponented to get the lambda for the Poisson distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrun_stan2 <- function(data_list, model_file = \"f1.c.stan\") {\n  mod <- cmdstan_model(model_file, exe_file = str_c(model_file, \".bin\"))\n  mod$sample(data_list, seed = 42, show_messages = FALSE, parallel_chains = 8)\n}\n\nctrs <- sort(unique(f2024$constructorRef))\ndrvs <- sort(unique(f2024$driverRef))\n\nctr_index <- tibble(constructorRef = ctrs, ctr_idx = 1:n_distinct(ctrs))\ndrv_index <- tibble(driverRef = drvs, drv_idx = 1:n_distinct(drvs))\n\nctr_drv_positions <- f2024 |>\n  select(constructorRef, driverRef, position) |>\n  arrange(constructorRef, driverRef) |>\n  merge(ctr_index) |>\n  merge(drv_index) |>\n  drop_na()\n\nsample_posterior2 <- function(fit) {\n  ctrs <- sort(unique(ctr_drv_positions$constructorRef))\n  drvs <- sort(unique(ctr_drv_positions$driverRef))\n  df_ctrs <- fit$draws(\"lambda_ctrs\", format = \"draws_matrix\") |> as_tibble()\n  colnames(df_ctrs) <- ctrs\n\n  df_drvs <- fit$draws(\"lambda_drvs\", format = \"draws_matrix\") |> as_tibble()\n  colnames(df_drvs) <- drvs\n\n  list(\n    ctrs = df_ctrs |>\n      pivot_longer(\n        all_of(ctrs),\n        names_to = \"constructorRef\", values_to = \"performance\"\n      ) |>\n      mutate(performance = as.double(performance)),\n    drvs = df_drvs |>\n      pivot_longer(\n        all_of(drvs),\n        names_to = \"driverRef\", values_to = \"performance\"\n      ) |>\n      mutate(performance = as.double(performance))\n  )\n}\n\nfit.c <- run_stan2(\n  list(\n    n_ctrs = n_distinct(ctrs),\n    n_drvs = n_distinct(drvs),\n    n_obs = nrow(ctr_drv_positions),\n    ctr_mus = 0.2 * (-5 + suzuka_positions$position), # shift to centre on 0\n    ctr_sd = 0.67, # picked a wide SD because car performance evolved over the season\n    positions = ctr_drv_positions$position,\n    position_indices = ctr_drv_positions |> select(ctr_idx, drv_idx) |> as.matrix()\n  )\n)\n```\n:::\n\n\n\nLet's first have a look at the constructor performance as determined by the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_ctrs <- sample_posterior2(fit.c)$ctrs\n\nggplot(posterior_ctrs) +\n  aes(x = performance, fill = constructorRef) +\n  # facet_wrap(~constructorRef) +\n  scale_fill_manual(values = ctr_colours$colour) +\n  geom_density(alpha = 0.5, colour = \"black\", linewidth = 0.2, show.legend = TRUE)\n```\n\n::: {.cell-output-display}\n![Constructor performance parameters determined by model. Lower (left) is better.](f1_files/figure-html/fig-ctr-perf-1.png){#fig-ctr-perf width=672}\n:::\n:::\n\n::: {#tbl-ctr-perf .cell tbl-cap='Constructor performance means and SDs from the posterior.'}\n\n```{.r .cell-code}\nposterior_ctrs |>\n  group_by(constructorRef) |>\n  summarise(mean_performance = mean(performance), sd = sd(performance)) |>\n  arrange(mean_performance) |>\n  mutate(rank = rank(mean_performance)) |>\n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|constructorRef | mean_performance|   sd| rank|\n|:--------------|----------------:|----:|----:|\n|red_bull       |             0.57| 0.19|    1|\n|ferrari        |             0.70| 0.21|    2|\n|mclaren        |             0.75| 0.23|    3|\n|mercedes       |             0.95| 0.26|    4|\n|aston_martin   |             1.18| 0.36|    5|\n|haas           |             1.31| 0.28|    6|\n|rb             |             1.34| 0.34|    7|\n|alpine         |             1.55| 0.31|    8|\n|williams       |             1.62| 0.30|    9|\n|sauber         |             1.66| 0.36|   10|\n\n\n:::\n:::\n\n\n\nNote that the sampled parameter is now latent performance not positions, so the numbers don't have a real-world meaning. What matters is relative performance, where a lower number is better.\n\nThe model suggests - controversially, but with appropriate uncertainty - that the Red Bull was the fastest car, followed by Ferrari and _then_ the McLaren. However the relative positioning of the other teams seems about right.\n\nForgive me for not labelling all the drivers on this next plot, but there's only so much plot fiddling I'm willing to do and it's usually obvious which is which.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_drvs <- sample_posterior2(fit.c)$drvs |> #|\n  merge(ctr_drvs) |>\n  group_by(driverRef) |>\n  mutate(x = mean(performance))\n\nggplot(posterior_drvs) +\n  aes(x = performance, fill = driverRef, label = driverRef) +\n  facet_wrap(~constructorRef) +\n  scale_fill_manual(values = drv_colours$colour) +\n  geom_density(alpha = 0.5, colour = \"black\", linewidth = 0.2, show.legend = FALSE) +\n  geom_text(data = posterior_drvs, mapping = aes(x = x, y = 0.75, angle = 90), check_overlap = TRUE)\n```\n\n::: {.cell-output-display}\n![Driver performance parameters determined by model. Lower (left) is better.](f1_files/figure-html/fig-drv-perf-1.png){#fig-drv-perf width=672}\n:::\n:::\n\n::: {#tbl-drv-perf .cell tbl-cap='Driver performance means and SDs from the posterior.'}\n\n```{.r .cell-code}\nposterior_drvs |>\n  group_by(driverRef) |>\n  summarise(mean_performance = mean(performance), sd = sd(performance)) |>\n  arrange(mean_performance) |>\n  mutate(rank = rank(mean_performance)) |>\n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|driverRef       | mean_performance|   sd| rank|\n|:---------------|----------------:|----:|----:|\n|max_verstappen  |             0.55| 0.20|    1|\n|leclerc         |             0.68| 0.22|    2|\n|norris          |             0.71| 0.24|    3|\n|russell         |             0.78| 0.26|    4|\n|colapinto       |             0.81| 0.31|    5|\n|hamilton        |             0.83| 0.26|    6|\n|sainz           |             0.86| 0.22|    7|\n|piastri         |             0.88| 0.24|    8|\n|gasly           |             0.89| 0.32|    9|\n|albon           |             0.93| 0.31|   10|\n|ocon            |             1.03| 0.31|   11|\n|hulkenberg      |             1.06| 0.29|   12|\n|zhou            |             1.06| 0.36|   13|\n|bottas          |             1.08| 0.36|   14|\n|alonso          |             1.11| 0.36|   15|\n|bearman         |             1.12| 0.29|   16|\n|tsunoda         |             1.13| 0.34|   17|\n|doohan          |             1.16| 0.37|   18|\n|sargeant        |             1.19| 0.31|   19|\n|ricciardo       |             1.20| 0.34|   20|\n|kevin_magnussen |             1.25| 0.29|   21|\n|lawson          |             1.26| 0.35|   22|\n|stroll          |             1.36| 0.36|   23|\n|perez           |             1.49| 0.21|   24|\n\n\n:::\n:::\n\n\n\nThe model suggests that the top drivers performed similarly, with Verstappen fastest. Poor Perez comes dead last, because the model has decided that the Red Bull was the fastest car.\n\nThere are some obvious issues though. Alonso is considered only the 15th best performer out of 24, which is absurd. This could be because the Suzuka prior placed Aston Martin ahead of Mercedes whereas they actually finished the season well behind.\n\nIf the informative prior is so bad, why don't we just use uninformative priors? If we do that the model will not be willing/able to distinguish the contribution from cars and drivers. We need a better prior.\n\nThere will also be some effect from the way I've simply excluded DNFs rather than penalising driver-fault DNFs.\n\n# Weaknesses of this model\n\nTo an extent I'm just role-playing being Dr Phillips here, so your number one takeaway should be: prefer the F1 Metrics model or the Bell et al. (2016) model, which is a much more sophisticated Bayesian model. If you are seriously interested in estimating driver performance, please check those out.\n\nNonetheless, there are some obvious weaknesses in this model that it's worth highlighting.\n\n## Use of positions rather than points\n\nPhillips makes a good argument for a non-linear reward function, for it punishes drivers more fairly for DNFs. That would be an improvement here.\n\n## No assignment of DNF blame\n\nI've just discarded all that data, which flatters the DNF-prone drivers. Though I note that the drivers near the bottom of the performance rankings in my model were more DNF-prone in 2024 anyway, so perhaps there's a correlation between low performance and DNFs, or those drivers had some races where they wounded the car but finished anyway.\n\n## Only a single season considered\n\nWith more data for each driver - across different cars - the model would be better able to distinguish driver and car performance. Note that it would be necessary to model each constructor by year because the car performance varies so much.\n\nThis suggests that we might benefit from having multiple representations of car performance within each year, e.g. splitting each team into A and B specs according to when they brought their largest upgrade. The challenge with that (apart from the tedious business of determining the break points) is that we'd have less data for each car and also there are perhaps several step changes in performance throughout the season.\n\n# Summing it all up\n\nWhat did we learn?\n\n1. How to use Stan to sample the posterior for a Bayesian model in R.\n2. Very little about F1.\n\nPerhaps point 2 is under-selling a little, since we did learn that Suzuka is quite good for assessing relative constructor performance, and the model turned out some reasonable results for car and driver performance. There are some major caveats of couse, but it is the kind of model we could build on. An obvious future step is to look at the other car-limited tracks - hopefully some that are at a different point in the season and have more slow corners than Suzuka - and make the prior a combination of results at these tracks. If I try that out in future I'll be sure to post an update here.",
    "supporting": [
      "f1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}